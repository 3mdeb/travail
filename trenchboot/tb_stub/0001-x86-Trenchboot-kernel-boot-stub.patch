From 675212f14251f6d6d8a4578e82d7f9b1c210fef4 Mon Sep 17 00:00:00 2001
From: Ross Philipson <ross.philipson@oracle.com>
Date: Fri, 7 Sep 2018 16:47:22 -0400
Subject: [PATCH] x86: Trenchboot kernel boot stub

Signed-off-by: Ross Philipson <ross.philipson@oracle.com>
---
 arch/x86/Kconfig                   |   7 +++
 arch/x86/boot/Makefile             |   2 +-
 arch/x86/boot/compressed/Makefile  |   2 +
 arch/x86/boot/compressed/head_32.S |  21 +++++++
 arch/x86/boot/compressed/head_64.S |  21 +++++++
 arch/x86/boot/compressed/tb_stub.S | 123 +++++++++++++++++++++++++++++++++++++
 arch/x86/boot/compressed/tb_stub.h |  28 +++++++++
 7 files changed, 203 insertions(+), 1 deletion(-)
 create mode 100644 arch/x86/boot/compressed/tb_stub.S
 create mode 100644 arch/x86/boot/compressed/tb_stub.h

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 1aa4dd3b5687..83f32df62d41 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -1959,6 +1959,13 @@ config EFI_MIXED
 
 	   If unsure, say N.
 
+config TRENCHBOOT_STUB
+       bool "Trenchboot stub support"
+       select RELOCATABLE
+       ---help---
+          This kernel feature allows a bzImage to be loaded directly
+	  through Intel TXT or AMD SKINIT measured launch.
+
 config SECCOMP
 	def_bool y
 	prompt "Enable seccomp to safely compute untrusted bytecode"
diff --git a/arch/x86/boot/Makefile b/arch/x86/boot/Makefile
index 9b5adae9cc40..56340994d8c0 100644
--- a/arch/x86/boot/Makefile
+++ b/arch/x86/boot/Makefile
@@ -87,7 +87,7 @@ $(obj)/vmlinux.bin: $(obj)/compressed/vmlinux FORCE
 
 SETUP_OBJS = $(addprefix $(obj)/,$(setup-y))
 
-sed-zoffset := -e 's/^\([0-9a-fA-F]*\) [ABCDGRSTVW] \(startup_32\|startup_64\|efi32_stub_entry\|efi64_stub_entry\|efi_pe_entry\|input_data\|_end\|_ehead\|_text\|z_.*\)$$/\#define ZO_\2 0x\1/p'
+sed-zoffset := -e 's/^\([0-9a-fA-F]*\) [ABCDGRSTVW] \(startup_32\|startup_64\|efi32_stub_entry\|efi64_stub_entry\|efi_pe_entry\|tb_stub_entry\|input_data\|_end\|_ehead\|_text\|z_.*\)$$/\#define ZO_\2 0x\1/p'
 
 quiet_cmd_zoffset = ZOFFSET $@
       cmd_zoffset = $(NM) $< | sed -n $(sed-zoffset) > $@
diff --git a/arch/x86/boot/compressed/Makefile b/arch/x86/boot/compressed/Makefile
index 169c2feda14a..e836406c50a4 100644
--- a/arch/x86/boot/compressed/Makefile
+++ b/arch/x86/boot/compressed/Makefile
@@ -89,6 +89,8 @@ vmlinux-objs-$(CONFIG_EFI_STUB) += $(obj)/eboot.o $(obj)/efi_stub_$(BITS).o \
 	$(objtree)/drivers/firmware/efi/libstub/lib.a
 vmlinux-objs-$(CONFIG_EFI_MIXED) += $(obj)/efi_thunk_$(BITS).o
 
+vmlinux-objs-$(CONFIG_TRENCHBOOT_STUB) += $(obj)/tb_stub.o
+
 # The compressed kernel is built with -fPIC/-fPIE so that a boot loader
 # can place it anywhere in memory and it will still run. However, since
 # it is executed as-is without any ELF relocation processing performed
diff --git a/arch/x86/boot/compressed/head_32.S b/arch/x86/boot/compressed/head_32.S
index 37380c0d5999..2c83d9c99aff 100644
--- a/arch/x86/boot/compressed/head_32.S
+++ b/arch/x86/boot/compressed/head_32.S
@@ -208,6 +208,27 @@ fail:
 ENDPROC(efi32_stub_entry)
 #endif
 
+#ifdef CONFIG_TRENCHBOOT_STUB
+ENTRY(tb_stub_entry)
+	/*
+	 * On entry, %ebx has the entry offset. Put offset from beginning
+         * in %ebp to calculate offsets.
+	 */
+	movl	%ebx, %ebp
+	subl	$(tb_stub_entry - startup_32), %ebp
+
+	/*
+	 * Set up the stack. Use the boot stack which will get recycled
+	 * later in startup_32
+	 */
+	leal	boot_stack_end(%ebp), %esp
+
+	/* More room to work in tb_stub in the text section */
+	jmp	tb_stub
+
+ENDPROC(tb_stub_entry)
+#endif
+
 	.text
 relocated:
 
diff --git a/arch/x86/boot/compressed/head_64.S b/arch/x86/boot/compressed/head_64.S
index 64037895b085..42d57750faf9 100644
--- a/arch/x86/boot/compressed/head_64.S
+++ b/arch/x86/boot/compressed/head_64.S
@@ -248,6 +248,27 @@ ENTRY(efi32_stub_entry)
 ENDPROC(efi32_stub_entry)
 #endif
 
+#ifdef CONFIG_TRENCHBOOT_STUB
+ENTRY(tb_stub_entry)
+	/*
+	 * On entry, %ebx has the entry offset. Put offset from beginning
+         * in %ebp to calculate offsets.
+	 */
+	movl	%ebx, %ebp
+	subl	$(tb_stub_entry - startup_32), %ebp
+
+	/*
+	 * Set up the stack. Use the boot stack which will get recycled
+	 * later in startup_32
+	 */
+	leal	boot_stack_end(%ebp), %esp
+
+	/* More room to work in tb_stub in the text section */
+	jmp	tb_stub
+
+ENDPROC(tb_stub_entry)
+#endif
+
 	.code64
 	.org 0x200
 ENTRY(startup_64)
diff --git a/arch/x86/boot/compressed/tb_stub.S b/arch/x86/boot/compressed/tb_stub.S
new file mode 100644
index 000000000000..1040095c9327
--- /dev/null
+++ b/arch/x86/boot/compressed/tb_stub.S
@@ -0,0 +1,123 @@
+	.code32
+	.text
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <asm/segment.h>
+#include <asm/boot.h>
+#include <asm/msr.h>
+#include <asm/processor-flags.h>
+#include <asm/asm-offsets.h>
+#include <asm/bootparam.h>
+#include "tb_stub.h"
+
+	.code32
+ENTRY(tb_stub)
+	cli
+	cld
+
+	/*
+	 * %ebp has old base address from head_BITS.S. Need to figure out
+	 * where we are now. Already have a stack so use a call.
+	 */
+	call	1f
+1:	popl	%ebp
+	subl	$1b, %ebp
+
+	/* On entry, only %cs is known good */
+	addl	%ebp, (tb_gdt + 2)(%ebp)
+	lgdt	tb_gdt(%ebp)
+
+	movl	$(__TB32_DS), %eax
+	movw	%ax, %ds
+	movw	%ax, %es
+	movw	%ax, %fs
+	movw	%ax, %gs
+	movw	%ax, %ss
+
+	leal	.Ltb_cs(%ebp), %eax
+	pushl	$(__TB32_CS)
+	pushl	%eax
+	lret
+
+.Ltb_cs:
+	/* Before going any further, make sure this is the BSP */
+	movl	$(MSR_IA32_APICBASE), %ecx
+	rdmsr
+	testl	$(MSR_IA32_APICBASE_BSP), %eax
+	jnz	.Lbsp_ok
+	ud2
+
+.Lbsp_ok:
+	/* Assume CPU is AMD to start */
+	movl	$(CPU_AMD), %edi
+
+	/* Now see if it is Intel */
+	movl	$0x0, %eax
+	cpuid
+	cmpl	$0x756e6547, %ebx # GenuineIntel?
+	jnz	.Lcpu_check_done
+	cmpl	$0x49656e69, %edx
+	jnz	.Lcpu_check_done
+	cmpl	$0x6c65746e, %ecx
+	jnz	.Lcpu_check_done
+	movl	$(CPU_INTEL), %edi
+
+.Lcpu_check_done:
+	/* Now that we know what CPU it is, do vendor specific operations */
+	cmpl	$(CPU_AMD), %edi
+	jz	.Ldo_amd
+
+	/* Enable SMI with GETSET[SMCTRL] */
+	xorl	%ebx, %ebx
+	movl	$(X86_GETSEC_SMCTRL), %eax
+	.byte 	0x0f, 0x37 /* GETSEC opcode */
+
+	/* An IRET-to-self can be used to unmask NMIs which SENTER masked */
+	leal	.Lunmask_nmi(%ebp), %eax
+	pushfl
+	pushl	$(__TB32_CS)
+	pushl	%eax
+	iret
+
+.Lunmask_nmi:
+	/* On Intel, the zero page address is passed in the TXT heap */
+	movl	$(TXT_PUB_CONFIG_REGS_BASE), %eax /* TXT MMIO pub regs */
+	movl	TXTCR_REG_HEAP_BASE(%eax), %ecx /* read size of BIOS data */
+	addl	%ecx, %eax /* skip over BIOS data to OS-MLE data */
+	movl	(%eax), %esi /* read zero page addr into %esi */
+
+	/* Clear the TXT error registers for a clean start of day */
+	movl	$(TXT_PRIV_CONFIG_REGS_BASE), %eax /* TXT MMIO priv regs */
+	movl	$0x0, TXTCR_ERRORCODE(%eax)
+	movl	$0xffffffff, TXTCR_ESTS(%eax)
+	jmp	.Ldone_intel
+
+.Ldo_amd:
+	/*
+	 * Disable maskable interrups in EFLAGS then enable global interrupts
+	 * including SMI and NMI (GIF).
+	 */
+	cli
+	stgi
+
+	/* On AMD %esi is set up by the Landing Zone, just go on */
+
+.Ldone_intel:
+	/* Enable MCE */
+	movl	%cr4, %eax
+	orl	$(X86_CR4_MCE), %eax
+	movl	%eax, %cr4
+
+	/* Done, jump to normal 32b pm entry */
+	movl	BP_code32_start(%esi), %eax
+	leal	startup_32(%eax), %eax
+	jmp	*%eax
+ENDPROC(tb_stub)
+
+tb_gdt:
+	.word	tb_gdt_end - tb_gdt
+	.long	tb_gdt
+	.word	0
+	.quad	0x00cf9a000000ffff	/* __TB32_CS */
+	.quad	0x00cf92000000ffff	/* __TB32_DS */
+tb_gdt_end:
diff --git a/arch/x86/boot/compressed/tb_stub.h b/arch/x86/boot/compressed/tb_stub.h
new file mode 100644
index 000000000000..bb2ffda39d79
--- /dev/null
+++ b/arch/x86/boot/compressed/tb_stub.h
@@ -0,0 +1,28 @@
+#ifndef BOOT_COMPRESSED_TRENCHBOOT_H
+#define BOOT_COMPRESSED_TRENCHEBOOT_H
+
+#define __TB32_CS 0x0008
+#define __TB32_DS 0x0010
+
+#define CPU_AMD   1
+#define CPU_INTEL 2
+
+#define X86_GETSEC_SMCTRL        7
+
+#define TXT_PUB_CONFIG_REGS_BASE  0xfed30000
+#define TXT_PRIV_CONFIG_REGS_BASE 0xfed20000
+#define TXTCR_STS                 0x0000
+#define TXTCR_ESTS                0x0008
+#define TXTCR_ERRORCODE           0x0030
+#define TXTCR_REG_HEAP_BASE       0x0300
+
+#ifndef __ASSEMBLY__
+
+struct os_mle_data {
+	uint32_t zero_page_addr;
+	/* TODO more to define later, may move to a common Trenchboot header */
+} __attribute__((packed));
+
+#endif
+
+#endif /* BOOT_COMPRESSED_TRENCHBOOT_H */
-- 
2.13.6

