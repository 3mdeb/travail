From 57b3d55ef80374d1d5c4f82b834a55fb77391439 Mon Sep 17 00:00:00 2001
From: Ross Philipson <ross.philipson@oracle.com>
Date: Fri, 26 Oct 2018 16:13:03 -0400
Subject: [PATCH 6/8] x86: Secure Launch kernel late boot stub

The routine slaunch_setup is called out of the x86 specific setup_arch
routine during early kernel boot. After determining what platform is present,
various operations specific to that platform occur. This includes finalizing
setting for the platform late launch and verifying that memory protections
are in place.

For TXT, this code also reserves the original compressed kernel setup area
where the APs were left looping so that this memory cannot be used.

Signed-off-by: Ross Philipson <ross.philipson@oracle.com>
---
 arch/x86/kernel/Makefile  |   1 +
 arch/x86/kernel/setup.c   |   5 +
 arch/x86/kernel/slaunch.c | 342 ++++++++++++++++++++++++++++++++++++++++++++++
 drivers/iommu/dmar.c      |   5 +
 4 files changed, 353 insertions(+)
 create mode 100644 arch/x86/kernel/slaunch.c

diff --git a/arch/x86/kernel/Makefile b/arch/x86/kernel/Makefile
index 8824d01c0c35..798a7dc44c83 100644
--- a/arch/x86/kernel/Makefile
+++ b/arch/x86/kernel/Makefile
@@ -70,6 +70,7 @@ obj-$(CONFIG_X86_32)		+= tls.o
 obj-$(CONFIG_IA32_EMULATION)	+= tls.o
 obj-y				+= step.o
 obj-$(CONFIG_INTEL_TXT)		+= tboot.o
+obj-$(CONFIG_SECURE_LAUNCH_STUB) += slaunch.o
 obj-$(CONFIG_ISA_DMA_API)	+= i8237.o
 obj-$(CONFIG_STACKTRACE)	+= stacktrace.o
 obj-y				+= cpu/
diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index b4866badb235..5784e638a12c 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -117,6 +117,7 @@
 #include <asm/microcode.h>
 #include <asm/kaslr.h>
 #include <asm/unwind.h>
+#include <asm/slaunch.h>
 
 /*
  * max_low_pfn_mapped: highest direct mapped pfn under 4GB
@@ -1037,6 +1038,10 @@ void __init setup_arch(char **cmdline_p)
 	early_gart_iommu_check();
 #endif
 
+#ifdef CONFIG_SECURE_LAUNCH_STUB
+	slaunch_setup();
+#endif
+
 	/*
 	 * partially used pages are not usable - thus
 	 * we are rounding upwards:
diff --git a/arch/x86/kernel/slaunch.c b/arch/x86/kernel/slaunch.c
new file mode 100644
index 000000000000..9e6f2879461c
--- /dev/null
+++ b/arch/x86/kernel/slaunch.c
@@ -0,0 +1,342 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2019 Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2019 Apertus Solutions, LLC
+ *
+ * Author(s):
+ *     Daniel P. Smith <dpsmith@apertussolutions.com>
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/security.h>
+#include <linux/memblock.h>
+#include <asm/segment.h>
+#include <asm/boot.h>
+#include <asm/msr.h>
+#include <asm/processor-flags.h>
+#include <asm/asm-offsets.h>
+#include <asm/e820/api.h>
+#include <asm/bootparam.h>
+#include <asm/setup.h>
+#include <asm/slaunch.h>
+
+#define PREFIX	"SLAUNCH: "
+
+static u32 sl_flags = 0;
+
+/* This should be plenty of room */
+static u8 txt_dmar[PAGE_SIZE] __attribute__((aligned(16)));
+
+u32 slaunch_get_flags(void)
+{
+	return sl_flags;
+}
+
+struct acpi_table_header *slaunch_get_dmar_table(struct acpi_table_header *dmar)
+{
+	/* The DMAR is only stashed and provided via TXT on Intel systems */
+	if (memcmp(txt_dmar, "DMAR", 4))
+		return dmar;
+
+	return (struct acpi_table_header*)(&txt_dmar[0]);
+}
+
+static void slaunch_txt_reset(void __iomem *txt, const char *msg, u64 error)
+{
+	u64 one = 1, val;
+
+	printk(KERN_ERR PREFIX "%s", msg);
+
+	memcpy_toio(txt + TXTCR_ERRORCODE, &error, sizeof(u64));
+	memcpy_fromio(&val, txt + TXTCR_E2STS, sizeof(u64));
+	memcpy_toio(txt + TXTCR_CMD_UNLOCK_MEM_CONFIG, &one, sizeof(u64));
+	memcpy_fromio(&val, txt + TXTCR_E2STS, sizeof(u64));
+	memcpy_toio(txt + TXTCR_CMD_RESET, &one, sizeof(u64));
+
+	for ( ; ; )
+		__asm__ __volatile__ ("pause");
+}
+
+void __iomem *txt_early_get_heap_table(u32 type, u32 bytes)
+{
+	void __iomem *txt;
+	void __iomem *heap;
+	u64 base, size, offset = 0;
+	int i;
+
+	if (type > TXT_SINIT_MLE_DATA_TABLE) {
+		printk(KERN_ERR PREFIX
+		       "Error invalid type for early heap walk\n");
+		return NULL;
+	}
+
+	txt = early_ioremap(TXT_PRIV_CONFIG_REGS_BASE,
+			    TXT_NR_CONFIG_PAGES * PAGE_SIZE);
+	if (!txt) {
+		/* This should not occur, no recovery possible */
+		panic("Error early_ioremap of TXT registers for heap walk\n");
+	}
+
+	memcpy_fromio(&base, txt + TXTCR_HEAP_BASE, sizeof(u64));
+	memcpy_fromio(&size, txt + TXTCR_HEAP_SIZE, sizeof(u64));
+
+	/*
+	 * The TXT heap is too big to map all at once with early_ioremap
+	 * so it is done a table at a time.
+	 */
+	for (i = 0; i < type; i++) {
+		base += offset;
+		heap = early_ioremap(base, sizeof(u64));
+		if (!heap)
+			slaunch_txt_reset(txt,
+				"Error early_ioremap of heap for heap walk\n",
+				TXT_SLERROR_HEAP_WALK);
+
+		memcpy_fromio(&offset, heap, sizeof(u64));
+		early_iounmap(heap, sizeof(u64));
+	}
+
+	/* Skip the size field at the head of each table */
+	base += sizeof(u64);
+	heap = early_ioremap(base, bytes);
+	if (!heap)
+		slaunch_txt_reset(txt,
+				  "Error early_ioremap of heap section\n",
+				  TXT_SLERROR_HEAP_MAP);
+
+	early_iounmap(txt, TXT_NR_CONFIG_PAGES * PAGE_SIZE);
+
+	return heap;
+}
+
+static int slaunch_txt_reserve_range(u64 base, u64 size)
+{
+	int type;
+
+	type = e820__get_entry_type(base, base + size - 1);
+	if (type == E820_TYPE_RAM) {
+		e820__range_update(base, size, E820_TYPE_RAM,
+				   E820_TYPE_RESERVED);
+		return 1;
+	}
+
+	return 0;
+}
+
+/*
+ * For Intel, certaion reqions of memory must be marked as reserved in the e820
+ * memory map if they are not already. This includes the TXT HEAP, the ACM area,
+ * the TXT private register bank. Normally these are properly reserved by
+ * firmware but if it was not done, do it now.
+ *
+ * Also the Memory Descriptor Ranges that are passed to the MLE (see TXT
+ * specification) may need to be reserved depeding on their type.
+ */
+static void slaunch_txt_reserve(void __iomem *txt)
+{
+	struct txt_memory_descriptor_record *mdr;
+	void __iomem *heap;
+	u64 base, size;
+	u32 mdrvals[2];
+	u32 i;
+	int updated = 0;
+
+	base = TXT_PRIV_CONFIG_REGS_BASE;
+	size = TXT_PUB_CONFIG_REGS_BASE - TXT_PRIV_CONFIG_REGS_BASE;
+	updated += slaunch_txt_reserve_range(base, size);
+
+	memcpy_fromio(&base, txt + TXTCR_HEAP_BASE, sizeof(u64));
+	memcpy_fromio(&size, txt + TXTCR_HEAP_SIZE, sizeof(u64));
+	updated += slaunch_txt_reserve_range(base, size);
+
+	memcpy_fromio(&base, txt + TXTCR_SINIT_BASE, sizeof(u64));
+	memcpy_fromio(&size, txt + TXTCR_SINIT_SIZE, sizeof(u64));
+	updated += slaunch_txt_reserve_range(base, size);
+
+	heap = txt_early_get_heap_table(TXT_SINIT_MLE_DATA_TABLE,
+					TXT_SINIT_MLE_NUMBER_MDRS + 8);
+	if (!heap)
+		slaunch_txt_reset(txt,
+				  "Error early_ioremap of MDR values\n",
+				  TXT_SLERROR_HEAP_MDR_VALS);
+	memcpy_fromio(&mdrvals[0], heap + TXT_SINIT_MLE_NUMBER_MDRS,
+		      sizeof(u64));
+
+	early_iounmap(heap, TXT_SINIT_MLE_NUMBER_MDRS + 8);
+
+	if (!mdrvals[0])
+		goto out;
+
+	heap = txt_early_get_heap_table(TXT_SINIT_MLE_DATA_TABLE,
+					mdrvals[1] +
+					(mdrvals[0]*sizeof(struct txt_memory_descriptor_record)));
+	if (!heap)
+		slaunch_txt_reset(txt,
+				  "Error early_ioremap of MDRs\n",
+				  TXT_SLERROR_HEAP_MDRS_MAP);
+
+	mdr = (struct txt_memory_descriptor_record *)(heap + mdrvals[1] - 8);
+
+	for (i = 0; i < mdrvals[0]; i++, mdr++) {
+		/* Spec says some entries can have length 0, ignore them */
+		if (mdr->type > 0 && mdr->length > 0)
+			updated += slaunch_txt_reserve_range(mdr->address,
+							     mdr->length);
+	}
+
+	early_iounmap(heap, mdrvals[1] +
+		      (mdrvals[0]*sizeof(struct txt_memory_descriptor_record)));
+
+out:
+	if (updated) {
+		e820__update_table(e820_table);
+		printk(KERN_INFO "TXT altered physical RAM map:\n");
+		e820__print_table("TXT-reserve");
+	}
+}
+
+/*
+ * TXT stashes a safe copy of the DMAR ACPI table to prevent tampering.
+ * It is stored in the TXT heap. Fetch it from there and make it available
+ * to the IOMMU driver.
+ */
+static void slaunch_copy_dmar_table(void __iomem *txt)
+{
+	void __iomem *heap;
+	u32 dmarvals[2];
+	u64 base, size;
+
+	memset(&txt_dmar, 0, PAGE_SIZE);
+
+	memcpy_fromio(&base, txt + TXTCR_HEAP_BASE, sizeof(u64));
+	memcpy_fromio(&size, txt + TXTCR_HEAP_SIZE, sizeof(u64));
+
+	heap = txt_early_get_heap_table(TXT_SINIT_MLE_DATA_TABLE,
+					TXT_SINIT_MLE_DMAR_TABLE_SIZE + 8);
+	if (!heap)
+		slaunch_txt_reset(txt,
+				  "Error early_ioremap of DMAR values\n",
+				  TXT_SLERROR_HEAP_DMAR_VALS);
+	memcpy_fromio(&dmarvals[0], heap + TXT_SINIT_MLE_DMAR_TABLE_SIZE,
+		      sizeof(u64));
+
+	early_iounmap(heap, TXT_SINIT_MLE_DMAR_TABLE_SIZE + 8);
+
+	if (!dmarvals[0] || !dmarvals[1])
+		slaunch_txt_reset(txt,
+				  "Error invalid DMAR table values\n",
+				  TXT_SLERROR_HEAP_INVALID_DMAR);
+
+	if (unlikely(dmarvals[0] > PAGE_SIZE))
+		slaunch_txt_reset(txt,
+				  "Error DMAR too big to store\n",
+				  TXT_SLERROR_HEAP_DMAR_SIZE);
+
+
+	heap = txt_early_get_heap_table(TXT_SINIT_MLE_DATA_TABLE, dmarvals[0]);
+	if (!heap)
+		slaunch_txt_reset(txt,
+				  "Error early_ioremap of DMAR\n",
+				  TXT_SLERROR_HEAP_DMAR_MAP);
+
+	memcpy_fromio(&txt_dmar[0], (void*)(heap + dmarvals[1] - 8),
+		      dmarvals[0]);
+
+	early_iounmap(heap, dmarvals[0]);
+}
+
+/*
+ * Intel specific late stub setup and validation.
+ */
+static void slaunch_setup_intel(void)
+{
+	void __iomem *txt;
+	u64 val = 0x1ULL;
+	phys_addr_t base;
+
+	txt = early_ioremap(TXT_PRIV_CONFIG_REGS_BASE,
+			    TXT_NR_CONFIG_PAGES * PAGE_SIZE);
+	if (!txt) {
+		/* This is really bad, no where to go from here */
+		panic("Error early_ioremap of TXT registers\n");
+	}
+
+	/*
+	 * Try to read the Intel VID from the TXT private registers to see if
+	 * TXT is active and the measured launch happened.
+	 */
+	memcpy_fromio(&val, txt + TXTCR_DIDVID, sizeof(u64));
+	if ((u16)(val & 0xffff) != 0x8086) {
+		/*
+		 * Can't do a proper TXT reset since it appears we are not in
+		 * SMX mode.
+		 */
+		panic("Invalid TXT vendor ID, not in SMX mode\n");
+	}
+
+	/*
+	 * Reading the proper DIDVID from the private register space means we
+	 * are in SMX mode and private registers are open for read/write.
+	 */
+
+	/* On Intel, have to handle TPM localities via TXT */
+	val = 0x1ULL;
+	memcpy_toio(txt + TXTCR_CMD_SECRETS, &val, sizeof(u64));
+	memcpy_fromio(&val, txt + TXTCR_E2STS, sizeof(u64));
+	val = 0x1ULL;
+	memcpy_toio(txt + TXTCR_CMD_OPEN_LOCALITY1, &val, sizeof(u64));
+	memcpy_fromio(&val, txt + TXTCR_E2STS, sizeof(u64));
+
+	slaunch_txt_reserve(txt);
+
+	/*
+	 * Protect the secure launch area in the .text section of the
+	 * protected mode enty area where the APs are idling. Note the
+	 * size we care about is far smaller than a page.
+	 */
+	base = boot_params.hdr.code32_start +
+		boot_params.hdr.slaunch_header;
+	if (memblock_reserve(base, PAGE_SIZE))
+		slaunch_txt_reset(txt,
+				  "Failed to reserve TXT AP wake area\n",
+				  TXT_SLERROR_RESERVE_AP_WAKE);
+
+	slaunch_copy_dmar_table(txt);
+
+	early_iounmap(txt, TXT_NR_CONFIG_PAGES * PAGE_SIZE);
+
+	/* TODO validate the PMRs */
+
+	printk(KERN_INFO "Intel TXT setup complete\n");
+}
+
+void slaunch_setup(void)
+{
+	u32 vendor[4];
+
+	/*
+	 * First assume Secure Launch is enabled and this is a
+	 * supported platform.
+	 */
+	sl_flags = SL_FLAG_ACTIVE;
+
+	cpuid(0, &vendor[0], &vendor[1], &vendor[2], &vendor[3]);
+
+	if (vendor[1] == 0x756e6547 &&        /* "Genu" */
+	    vendor[2] == 0x6c65746e &&        /* "ntel" */
+	    vendor[3] == 0x49656e69) {        /* "ineI" */
+		sl_flags |= SL_FLAG_ARCH_TXT;
+		slaunch_setup_intel();
+	} else if (vendor[1] == 0x68747541 && /* "Auth" */
+		   vendor[2] == 0x444d4163 && /* "cAMD" */
+		   vendor[3] == 0x69746e65) { /* "enti" */
+		panic("Invalid platform: AMD not supported\n");
+	} else {
+		panic("Invalid platform: not Intel or AMD\n");
+	}
+}
diff --git a/drivers/iommu/dmar.c b/drivers/iommu/dmar.c
index d9c748b6f9e4..5e9fc61da18e 100644
--- a/drivers/iommu/dmar.c
+++ b/drivers/iommu/dmar.c
@@ -41,6 +41,7 @@
 #include <linux/iommu.h>
 #include <asm/irq_remapping.h>
 #include <asm/iommu_table.h>
+#include <asm/slaunch.h>
 
 #include "irq_remapping.h"
 
@@ -632,7 +633,11 @@ parse_dmar_table(void)
 	 * ACPI tables may not be DMA protected by tboot, so use DMAR copy
 	 * SINIT saved in SinitMleData in TXT heap (which is DMA protected)
 	 */
+#ifdef CONFIG_SECURE_LAUNCH_STUB
+	dmar_tbl = slaunch_get_dmar_table(dmar_tbl);
+#else
 	dmar_tbl = tboot_get_dmar_table(dmar_tbl);
+#endif
 
 	dmar = (struct acpi_table_dmar *)dmar_tbl;
 	if (!dmar)
-- 
2.13.6

