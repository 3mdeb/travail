From ca8adc0d67827426925cd0726a19c448f1023ee2 Mon Sep 17 00:00:00 2001
From: Ross Philipson <ross.philipson@oracle.com>
Date: Tue, 2 Oct 2018 14:41:49 -0400
Subject: [PATCH 3/5] x86: Trenchboot SMP bringup support

Note the AP bringup is very different becuase SKINIT and the ACM leave
the APs in very different states post launch.

Signed-off-by: Ross Philipson <ross.philipson@oracle.com>
---
 arch/x86/include/asm/realmode.h      |  3 ++
 arch/x86/kernel/smpboot.c            | 46 ++++++++++++++++++++++++++
 arch/x86/realmode/init.c             |  1 +
 arch/x86/realmode/rm/header.S        |  3 ++
 arch/x86/realmode/rm/trampoline_64.S | 64 ++++++++++++++++++++++++++++++++++++
 5 files changed, 117 insertions(+)

diff --git a/arch/x86/include/asm/realmode.h b/arch/x86/include/asm/realmode.h
index 63b3393bd98e..260ae182b953 100644
--- a/arch/x86/include/asm/realmode.h
+++ b/arch/x86/include/asm/realmode.h
@@ -32,6 +32,9 @@ struct real_mode_header {
 #endif
 	/* APM/BIOS reboot */
 	u32	machine_real_restart_asm;
+#ifdef CONFIG_TRENCHBOOT_STUB
+	u32	tb_trampoline_start32;
+#endif
 #ifdef CONFIG_X86_64
 	u32	machine_real_restart_seg;
 #endif
diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c
index f02ecaf97904..93c595a83b63 100644
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -81,6 +81,7 @@
 #include <asm/cpu_device_id.h>
 #include <asm/spec-ctrl.h>
 #include <asm/hw_irq.h>
+#include <asm/trenchboot.h>
 
 /* representing HT siblings of each logical CPU */
 DEFINE_PER_CPU_READ_MOSTLY(cpumask_var_t, cpu_sibling_map);
@@ -740,6 +741,14 @@ wakeup_secondary_cpu_via_init(int phys_apicid, unsigned long start_eip)
 		apic_read(APIC_ESR);
 	}
 
+	/*
+	 * Only here after a measured launch via SKINIT on AMD. SKINIT
+	 * returns with INIT asserted on all the APs so do not send
+	 * INIT here. The rest would be the normal SIPI process and then
+	 * starting the AP in the realmode blob code.
+	 */
+#ifndef CONFIG_TRENCHBOOT_STUB
+
 	pr_debug("Asserting INIT\n");
 
 	/*
@@ -756,6 +765,8 @@ wakeup_secondary_cpu_via_init(int phys_apicid, unsigned long start_eip)
 
 	udelay(init_udelay);
 
+#endif
+
 	pr_debug("Deasserting INIT\n");
 
 	/* Target chip */
@@ -885,6 +896,15 @@ static int wakeup_cpu0_nmi(unsigned int cmd, struct pt_regs *regs)
 	return NMI_DONE;
 }
 
+#ifdef CONFIG_TRENCHBOOT_STUB
+
+static int
+wakeup_cpu_via_intel_txt(int cpu)
+{
+	return 0;
+}
+#endif
+
 /*
  * Wake up AP by INIT, INIT, STARTUP sequence.
  *
@@ -1010,6 +1030,8 @@ static int do_boot_cpu(int apicid, int cpu, struct task_struct *idle,
 	cpumask_clear_cpu(cpu, cpu_initialized_mask);
 	smp_mb();
 
+#ifndef CONFIG_TRENCHBOOT_STUB
+
 	/*
 	 * Wake up a CPU in difference cases:
 	 * - Use the method in the APIC driver if it's defined
@@ -1022,6 +1044,30 @@ static int do_boot_cpu(int apicid, int cpu, struct task_struct *idle,
 		boot_error = wakeup_cpu_via_init_nmi(cpu, start_ip, apicid,
 						     cpu0_nmi_registered);
 
+#else
+
+	/*
+	 * Halting and restarting the BSP is not supported in the Intermediate
+	 * Loader. Also this code path should not be taken if Trenchboot is
+	 * not active.
+	 */
+	BUG_ON(cpu == 0);
+	BUG_ON(!(boot_params.trenchboot_info.tb_flags & TB_FLAG_ACTIVE));
+
+	/*
+	 * Custom APIC driver configuration is not currently supported on AMD
+	 * and on Intel the startup is totally different.
+	 */
+	if (boot_params.trenchboot_info.tb_flags & TB_FLAG_ARCH_SKINIT)
+		boot_error = wakeup_cpu_via_init_nmi(cpu, start_ip, apicid,
+						     cpu0_nmi_registered);
+	else if (boot_params.trenchboot_info.tb_flags & TB_FLAG_ARCH_TXT)
+		boot_error = wakeup_cpu_via_intel_txt(cpu);
+	else
+		BUG();
+
+#endif
+
 	if (!boot_error) {
 		/*
 		 * Wait 10s total for first sign of life from AP
diff --git a/arch/x86/realmode/init.c b/arch/x86/realmode/init.c
index d10105825d57..57b96505d4c1 100644
--- a/arch/x86/realmode/init.c
+++ b/arch/x86/realmode/init.c
@@ -43,6 +43,7 @@ void __init reserve_real_mode(void)
 
 	memblock_reserve(mem, size);
 	set_real_mode_mem(mem, size);
+	/* TODO DEV protect this region */
 }
 
 static void __init setup_real_mode(void)
diff --git a/arch/x86/realmode/rm/header.S b/arch/x86/realmode/rm/header.S
index 30b0d30d861a..07b304553404 100644
--- a/arch/x86/realmode/rm/header.S
+++ b/arch/x86/realmode/rm/header.S
@@ -31,6 +31,9 @@ GLOBAL(real_mode_header)
 #endif
 	/* APM/BIOS reboot */
 	.long	pa_machine_real_restart_asm
+#ifdef CONFIG_TRENCHBOOT_STUB
+	.long	pa_tb_trampoline_start32
+#endif
 #ifdef CONFIG_X86_64
 	.long	__KERNEL32_CS
 #endif
diff --git a/arch/x86/realmode/rm/trampoline_64.S b/arch/x86/realmode/rm/trampoline_64.S
index 24bb7598774e..4e7083250165 100644
--- a/arch/x86/realmode/rm/trampoline_64.S
+++ b/arch/x86/realmode/rm/trampoline_64.S
@@ -32,6 +32,9 @@
 #include <asm/segment.h>
 #include <asm/processor-flags.h>
 #include <asm/realmode.h>
+#ifdef CONFIG_TRENCHBOOT_STUB
+#include <asm/trenchboot.h>
+#endif
 #include "realmode.h"
 
 	.text
@@ -42,6 +45,11 @@ ENTRY(trampoline_start)
 	cli			# We should be safe anyway
 	wbinvd
 
+	# Only here in RM code on AMD platforms post SKINIT launch
+#ifdef CONFIG_TRENCHBOOT_STUB
+	stgi
+#endif
+
 	LJMPW_RM(1f)
 1:
 	mov	%cs, %ax	# Code and data in the same place
@@ -86,6 +94,62 @@ no_longmode:
 	.section ".text32","ax"
 	.code32
 	.balign 4
+#ifdef CONFIG_TRENCHBOOT_STUB
+ENTRY(tb_trampoline_start32)
+	/*
+	 * Entry vectro for AP startup from TXT. On entry:
+	 *  - Protected mode
+	 *  - Paging disabled
+	 *  - %ebx has linear address of tb_trampoline_start
+	 *  - Only %cs is valid
+	 *  - MCE/SMI/NMI are all disabled
+	 * For the rest of the state of the world, see the Intel TXT manual
+	 */
+	cli
+	cld
+
+	lgdt	tr_gdt(%ebx)
+	lidt	tr_idt(%ebx)
+
+	/* Going to use the real mode stack since it is there */
+	movl	$pa_rm_stack_end, %esp
+
+	/* Enable MCE */
+	movl	%cr4, %eax
+	orl	$(X86_CR4_MCE), %eax
+	movl	%eax, %cr4
+
+	/* Enable SMI with GETSET[SMCTRL] */
+	pushl	%ebx
+	xorl	%ebx, %ebx
+	movl	$(X86_GETSEC_SMCTRL), %eax
+	.byte 	0x0f, 0x37 /* GETSEC opcode */
+	popl	%ebx
+
+	/* Enable NMI using an IRET-to-self */
+	leal	.Lnmi_enabled(%ebx), %eax
+	pushfl
+	pushl	$(__KERNEL32_CS)
+	pushl	%eax
+	iret
+
+.Lnmi_enabled:
+	addl	$12, %esp
+
+	movw	$__KERNEL_DS, %dx	# Data segment descriptor
+
+	/*
+	 * This may seem a little odd but this is what %esp would have had in
+	 * it on the jmp from real mode because all real mode fixups were done
+	 * via the code segment.
+	 */
+	movl	$rm_stack_end, %esp
+
+	/* Jump to where the 16b code would have jumped */
+	ljmpl	$__KERNEL32_CS, $pa_startup_32
+#endif
+
+	.balign 4
 ENTRY(startup_32)
 	movl	%edx, %ss
 	addl	$pa_real_mode_base, %esp
-- 
2.13.6

